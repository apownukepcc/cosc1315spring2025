{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNSjIvsclFkqokMDcNGqu6r"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wFVzI392w6uW","outputId":"852abb4a-7cb6-4a50-d2c4-ef24701e0292"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10000, Error: 0.174663\n","Epoch 101/10000, Error: 0.005864\n","Epoch 201/10000, Error: 0.002218\n","Epoch 301/10000, Error: 0.001298\n","Epoch 401/10000, Error: 0.000821\n","Epoch 501/10000, Error: 0.000520\n","Epoch 601/10000, Error: 0.000339\n","Epoch 701/10000, Error: 0.000233\n","Epoch 801/10000, Error: 0.000170\n","Epoch 901/10000, Error: 0.000130\n","Epoch 1001/10000, Error: 0.000104\n","Epoch 1101/10000, Error: 0.000086\n","Epoch 1201/10000, Error: 0.000074\n","Epoch 1301/10000, Error: 0.000064\n","Epoch 1401/10000, Error: 0.000057\n","Epoch 1501/10000, Error: 0.000051\n","Epoch 1601/10000, Error: 0.000047\n","Epoch 1701/10000, Error: 0.000043\n","Epoch 1801/10000, Error: 0.000040\n","Epoch 1901/10000, Error: 0.000037\n","Epoch 2001/10000, Error: 0.000035\n","Epoch 2101/10000, Error: 0.000032\n","Epoch 2201/10000, Error: 0.000031\n","Epoch 2301/10000, Error: 0.000029\n","Epoch 2401/10000, Error: 0.000027\n","Epoch 2501/10000, Error: 0.000026\n","Epoch 2601/10000, Error: 0.000025\n","Epoch 2701/10000, Error: 0.000023\n","Epoch 2801/10000, Error: 0.000022\n","Epoch 2901/10000, Error: 0.000021\n","Epoch 3001/10000, Error: 0.000020\n","Epoch 3101/10000, Error: 0.000019\n","Epoch 3201/10000, Error: 0.000019\n","Epoch 3301/10000, Error: 0.000018\n","Epoch 3401/10000, Error: 0.000017\n","Epoch 3501/10000, Error: 0.000016\n","Epoch 3601/10000, Error: 0.000016\n","Epoch 3701/10000, Error: 0.000015\n","Epoch 3801/10000, Error: 0.000015\n","Epoch 3901/10000, Error: 0.000014\n","Epoch 4001/10000, Error: 0.000014\n","Epoch 4101/10000, Error: 0.000013\n","Epoch 4201/10000, Error: 0.000013\n","Epoch 4301/10000, Error: 0.000013\n","Epoch 4401/10000, Error: 0.000012\n","Epoch 4501/10000, Error: 0.000012\n","Epoch 4601/10000, Error: 0.000012\n","Epoch 4701/10000, Error: 0.000011\n","Epoch 4801/10000, Error: 0.000011\n","Epoch 4901/10000, Error: 0.000011\n","Epoch 5001/10000, Error: 0.000011\n","Epoch 5101/10000, Error: 0.000010\n","Epoch 5201/10000, Error: 0.000010\n","Epoch 5301/10000, Error: 0.000010\n","Epoch 5401/10000, Error: 0.000010\n","Epoch 5501/10000, Error: 0.000010\n","Epoch 5601/10000, Error: 0.000009\n","Epoch 5701/10000, Error: 0.000009\n","Epoch 5801/10000, Error: 0.000009\n","Epoch 5901/10000, Error: 0.000009\n","Epoch 6001/10000, Error: 0.000009\n","Epoch 6101/10000, Error: 0.000009\n","Epoch 6201/10000, Error: 0.000009\n","Epoch 6301/10000, Error: 0.000009\n","Epoch 6401/10000, Error: 0.000009\n","Epoch 6501/10000, Error: 0.000008\n","Epoch 6601/10000, Error: 0.000008\n","Epoch 6701/10000, Error: 0.000008\n","Epoch 6801/10000, Error: 0.000008\n","Epoch 6901/10000, Error: 0.000008\n","Epoch 7001/10000, Error: 0.000008\n","Epoch 7101/10000, Error: 0.000008\n","Epoch 7201/10000, Error: 0.000008\n","Epoch 7301/10000, Error: 0.000008\n","Epoch 7401/10000, Error: 0.000008\n","Epoch 7501/10000, Error: 0.000008\n","Epoch 7601/10000, Error: 0.000008\n","Epoch 7701/10000, Error: 0.000008\n","Epoch 7801/10000, Error: 0.000007\n","Epoch 7901/10000, Error: 0.000007\n","Epoch 8001/10000, Error: 0.000007\n","Epoch 8101/10000, Error: 0.000007\n","Epoch 8201/10000, Error: 0.000007\n"]}],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Generate dataset\n","def generate_data(n_samples=10000, x_min=0, x_max=10):\n","    X = np.linspace(x_min, x_max, n_samples).reshape(-1, 1)\n","    y = X ** 2  # Quadratic function y = x^2\n","\n","    # Store original min/max for denormalization\n","    X_min, X_max = X.min(), X.max()\n","    y_min, y_max = y.min(), y.max()\n","\n","    # Normalize data\n","    X = (X - X_min) / (X_max - X_min)\n","    y = (y - y_min) / (y_max - y_min)\n","\n","    return X, y, X_min, X_max, y_min, y_max\n","\n","# Define activation functions and their derivatives\n","def relu(x):\n","    return np.maximum(0, x)\n","\n","def relu_derivative(x):\n","    return np.where(x > 0, 1, 0)\n","\n","def linear(x):\n","    return x\n","\n","def linear_derivative(x):\n","    return np.ones_like(x)\n","\n","activation_functions = {\n","    'relu': (relu, relu_derivative),\n","    'linear': (linear, linear_derivative)\n","}\n","\n","class NeuralNetwork:\n","    def __init__(self, layers, activations):\n","        self.layers = layers\n","        self.activations = activations\n","        self.weights = []\n","        self.biases = []\n","        self.initialize_weights()\n","\n","    def initialize_weights(self):\n","        for i in range(len(self.layers) - 1):\n","            weight = np.random.randn(self.layers[i], self.layers[i + 1]) * np.sqrt(1 / self.layers[i])  # Xavier Initialization\n","            bias = np.zeros((1, self.layers[i + 1]))\n","            self.weights.append(weight)\n","            self.biases.append(bias)\n","\n","    def feedforward(self, X):\n","        self.layer_outputs = [X]\n","        for i in range(len(self.weights)):\n","            activation, _ = activation_functions[self.activations[i]]\n","            X = activation(np.dot(X, self.weights[i]) + self.biases[i])\n","            self.layer_outputs.append(X)\n","        return X\n","\n","    def backpropagation(self, X, y, learning_rate):\n","        output_error = y - self.layer_outputs[-1]\n","        _, derivative = activation_functions[self.activations[-1]]\n","        deltas = [output_error * derivative(self.layer_outputs[-1])]\n","\n","        for i in reversed(range(len(deltas), len(self.weights))):\n","            _, derivative = activation_functions[self.activations[i]]\n","            delta = deltas[-1].dot(self.weights[i].T) * derivative(self.layer_outputs[i])\n","            deltas.append(delta)\n","        deltas.reverse()\n","\n","        for i in range(len(self.weights)):\n","            self.weights[i] += self.layer_outputs[i].T.dot(deltas[i]) * learning_rate\n","            self.biases[i] += np.sum(deltas[i], axis=0, keepdims=True) * learning_rate\n","\n","    def train(self, X, y, epochs, learning_rate):\n","        for epoch in range(epochs):\n","            self.feedforward(X)\n","            self.backpropagation(X, y, learning_rate)\n","            if epoch % 100 == 0 or epoch == epochs - 1:\n","                mse = np.mean(np.square(y - self.layer_outputs[-1]))\n","                print(f'Epoch {epoch + 1}/{epochs}, Error: {mse:.6f}')\n","\n","    def predict(self, X):\n","        return self.feedforward(X)\n","\n","# Generate dataset\n","X, y, X_min, X_max, y_min, y_max = generate_data()\n","\n","# Define network structure\n","input_size = 1\n","output_size = 1\n","hidden_layers = [10, 15, 10]\n","layers = [input_size] + hidden_layers + [output_size]\n","activations = ['relu', 'relu', 'relu', 'linear']\n","\n","# Initialize neural network\n","nn = NeuralNetwork(layers, activations)\n","\n","# Train the neural network\n","nn.train(X, y, epochs=10000, learning_rate=0.00001)\n","\n","# Predict values for all X\n","y_pred = nn.predict(X)\n","\n","# Denormalize predictions\n","y_pred_denorm = y_pred * (y_max - y_min) + y_min\n","\n","# Predict value for x=5\n","x_test = np.array([[5]])\n","x_test_norm = (x_test - X_min) / (X_max - X_min)  # Normalize x_test\n","\n","y_test_pred_norm = nn.predict(x_test_norm)\n","y_test_pred = y_test_pred_norm * (y_max - y_min) + y_min  # Denormalize prediction\n","y_exact = x_test ** 2  # Exact function value\n","print(f'Prediction for x=5: {y_test_pred[0][0]:.6f}, Exact value: {y_exact[0][0]:.6f}')\n","\n","# Plot original data and predictions\n","plt.figure(figsize=(10, 6))\n","plt.plot(X * (X_max - X_min) + X_min, y * (y_max - y_min) + y_min, label='Original Data', color='blue')\n","plt.scatter(X * (X_max - X_min) + X_min, y_pred_denorm, label='Predictions', color='red', s=10)\n","plt.scatter(x_test, y_test_pred, label=f'Prediction for x=5: {y_test_pred[0][0]:.2f}', color='green', s=100, marker='x')\n","plt.scatter(x_test, y_exact, label=f'Exact Value for x=5: {y_exact[0][0]:.2f}', color='orange', s=100, marker='o')\n","plt.title('Original Data vs Predictions')\n","plt.xlabel('X')\n","plt.ylabel('f(X) = X^2')\n","plt.legend()\n","plt.grid(True)\n","plt.show()"]}]}